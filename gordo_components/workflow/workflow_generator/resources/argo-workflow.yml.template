# Requires the following variables to render properly
# project_name: Name of the project this workflow is linked up to (e.g. "Grane")
# project_version: Current version of this project, e.g. the git commit-sha.
# containing start and end dates (if tags are shared across machines the earliest train start date and latest train end date is taken)
# model_builder_resources_requests_memory: Memory requests of the model builder in unit `M`
# model_builder_resources_requests_cpu: CPU requests of the model builder in unit `m`
# model_builder_resources_limits_memory: Memory limit of the model builder in unit `M`
# model_builder_resources_limits_cpu: CPU limit of the model builder in unit `m`

apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: {{project_name}}-{{project_version}}-
  annotations:
    gordo-models: '{{ machines|map(attribute="name")|list|tojson|safe }}'
  labels:
    app.kubernetes.io/managed-by: gordo
    applications.gordo.equinor.com/project-name: "{{project_name}}"
    applications.gordo.equinor.com/project-version: "{{project_version}}"
  {% if owner_references is defined %}
  ownerReferences: {{owner_references}}
  {% endif %}
spec:
  ttlSecondsAfterFinished: 115200 # 32 hours
  entrypoint: do-all
  onExit: sql-and-cleanup
  volumes:
  - name: azurefile
    persistentVolumeClaim:
      claimName: azurefile
  - name: datalake-access-token
    secret:
      secretName: datalake-access-token # Must be saved
  templates:
  - name: ensure-single-workflow
    # Ensures that only one version of workflows for a given project runs at the same time.
    # Deletes any workflows for the same project of different version
    retryStrategy:
      limit: 5
    metadata:
      labels:
        app: ensure-single-workflow
        applications.gordo.equinor.com/project-name: "{{project_name}}"
        applications.gordo.equinor.com/project-version: "{{project_version}}"
    script:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-deploy:{{cleanup_version}}
      command: [bash]
      source: |
        echo "Ensuring that no other versions of workflows for this project is running at the same time"
        # This fetches all the workflows of the same version as me, and finds the one of them with the earliest start-time
        export MY_CREATION_TIME=$(kubectl get workflows -l applications.gordo.equinor.com/project-name="$GORDO_PROJECT_NAME",applications.gordo.equinor.com/project-version=="$GORDO_PROJECT_VERSION",workflows.argoproj.io/phase=Running -o json | jq -r "[.items[] | {name: .metadata.name, startTime: .metadata.creationTimestamp | fromdate }] | sort_by(.startTime) |.[0]" | jq -r ".startTime")

        echo "Found that my creationTime was $MY_CREATION_TIME"
        # This function finds all running workflows of the same project but different version AND created earlier than $MY_CREATION_TIME
        function find_older_running_workflows {
            export RUNNING_WORKFLOWS=$(kubectl get workflows -l applications.gordo.equinor.com/project-name="$GORDO_PROJECT_NAME",applications.gordo.equinor.com/project-version!="$GORDO_PROJECT_VERSION",workflows.argoproj.io/phase=Running -o json | jq -r "[.items[] | {name: .metadata.name, startTime: .metadata.creationTimestamp | fromdate } | select(.startTime < $MY_CREATION_TIME)]" | jq -r ".[].name")
            echo "Running workflows:"
            echo "$RUNNING_WORKFLOWS"
        }
        find_older_running_workflows

        while [[ $RUNNING_WORKFLOWS != "" ]]; do
            echo "Deleting and checking again"
            kubectl delete --wait=True workflows $RUNNING_WORKFLOWS
            sleep 10
            find_older_running_workflows
        done
        echo "No other versions of workflows for this project found, exiting successfully"

      resources:
        requests:
          memory: "100M"
          cpu: "2m"
        limits:
          memory: "200M"
          cpu: "100m"
      env:
      - name: GORDO_PROJECT_NAME
        value: "{{project_name}}"
      - name: GORDO_PROJECT_VERSION
        value: "{{project_version}}"


  - name: gordo-influx-service
    retryStrategy:
      limit: 5
    resource:
      action: apply
      manifest: |
        apiVersion: v1
        kind: Service
        metadata:
          name: gordo-influx-{{project_name}}
          labels:
            app: gordo-influx-{{project_name}}
            app.kubernetes.io/name: influx
            app.kubernetes.io/component: service
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
         {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
        {% endif %}
        spec:
          selector:
            app: gordo-influx-{{project_name}}
          ports:
          - port: 8086
            name: api
            targetPort: 8086
  - name: gordo-influx-statefulset
    retryStrategy:
      limit: 5
    resource:
      action: apply
      successCondition: status.readyReplicas > 0
      manifest: |
        apiVersion: apps/v1
        kind: StatefulSet
        metadata:
          name: gordo-influx-{{project_name}}
          labels:
            app: gordo-influx-{{project_name}}
            app.kubernetes.io/name: influxd-deployment
            app.kubernetes.io/component: influxdb
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
        {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
        {% endif %}
        spec:
          serviceName: gordo-influx-{{project_name}}
          volumeClaimTemplates:
            - metadata:
                name: influx-storage-{{project_version}}
                labels:
                  applications.gordo.equinor.com/project-name: "{{project_name}}"
                  applications.gordo.equinor.com/project-version: "{{project_version}}"
                  app.kubernetes.io/part-of: gordo
                  app.kubernetes.io/managed-by: gordo
                annotations:
                  applications.gordo.equinor.com/project-name: "{{project_name}}"
                  applications.gordo.equinor.com/project-version: "{{project_version}}"
                {% if owner_references is defined %}
                ownerReferences: {{owner_references}}
                {% endif %}
              spec:
                accessModes: [ "ReadWriteOnce" ]
                storageClassName: "managed-premium"
                resources:
                  requests:
                    storage: 28Gi
          selector:
            matchLabels:
              app: gordo-influx-{{project_name}}
          replicas: 1
          template:
            metadata:
              labels:
                app: gordo-influx-{{project_name}}
              {% if owner_references is defined %}
              ownerReferences: {{owner_references}}
              {% endif %}
            spec:
              containers:
              - image: "influxdb:1.7.6-alpine"
                imagePullPolicy: "IfNotPresent"
                name: gordo-influx-{{project_name}}
                volumeMounts:
                  - name: influx-storage-{{project_version}}
                    mountPath: /var/lib/influxdb
                ports:
                  - name: api
                    containerPort: 8086
                resources:
                  requests:
                    memory: "{{ influx_resources_requests_memory }}M"
                    cpu: "{{ influx_resources_requests_cpu }}m"
                  limits:
                    memory: "{{ influx_resources_limits_memory }}M"
                    cpu: "{{ influx_resources_limits_cpu }}m"
                livenessProbe:
                  httpGet:
                    path: /ping
                    port: api
                  initialDelaySeconds: 30
                  timeoutSeconds: 5
                readinessProbe:
                  httpGet:
                    path: /ping
                    port: api
                  initialDelaySeconds: 5
                  timeoutSeconds: 1

  - name: gordo-influx-database-creator
    retryStrategy:
      limit: 5
    script:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-deploy:{{cleanup_version}}
      command: [bash]
      source: |
        echo "Creating feeder database for influx for project {{project_name}}" \
        && curl -i -XPOST http://gordo-influx-{{project_name}}:8086/query --data-urlencode "q=CREATE DATABASE feeder"
      resources:
        requests:
          memory: 50M
          cpu: 10m
        limits:
          memory: 1G


  - name: gordo-influx
    steps:
    - - name: gordo-influx-statefulset
        template: gordo-influx-statefulset
    - - name: gordo-influx-service
        template: gordo-influx-service
    - - name: gordo-influx-database-creator
        template: gordo-influx-database-creator

  - name: gordo-grafana-service
    retryStrategy:
      limit: 5
    resource:
      action: apply
      manifest: |
        ---
        apiVersion: v1
        kind: Service
        metadata:
          name: gordo-grafana-{{project_name}}
          labels:
            app: gordo-grafana-{{project_name}}
            app.kubernetes.io/name: grafana
            app.kubernetes.io/component: service
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          selector:
            app: gordo-grafana-{{project_name}}
          ports:
          - port: 3000
            name: api
            targetPort: 3000

  - name: gordo-grafana-statefulset
    retryStrategy:
      limit: 5
    resource:
      action: apply
      successCondition: status.readyReplicas > 0
      manifest: |
        apiVersion: apps/v1
        kind: StatefulSet
        metadata:
          name: gordo-grafana-{{project_name}}
          labels:
            app: gordo-grafana-{{project_name}}
            app.kubernetes.io/name: grafanad-deployment
            app.kubernetes.io/component: grafanadb
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          serviceName: gordo-grafana-{{project_name}}
          selector:
            matchLabels:
              app: gordo-grafana-{{project_name}}
          replicas: 1
          template:
            metadata:
              labels:
                app: gordo-grafana-{{project_name}}
              {% if owner_references is defined %}
              ownerReferences: {{owner_references}}
              {% endif %}
            spec:
              containers:
              - image: "grafana/grafana:6.1.4"
                env:
                - name: GF_INSTALL_PLUGINS
                  value: "grafana-worldmap-panel,flant-statusmap-panel,vonage-status-panel"
                - name: GF_AUTH_ANONYMOUS_ENABLED
                  value: "true"
                - name: GF_AUTH_ANONYMOUS_ORG_ROLE
                  value: "Admin"
                - name: GF_AUTH_DISABLE_LOGIN_FORM
                  value: "true"
                - name: GF_AUTH_BASIC_ENABLED
                  value: "false"
                - name: SERVER_ENABLE_GZIP
                  value: "true"
                imagePullPolicy: "IfNotPresent"
                name: gordo-grafana-{{project_name}}
                ports:
                  - name: api
                    containerPort: 3000
                resources:
                  requests:
                    memory: 1G
                    cpu: 500m
                readinessProbe:
                  httpGet:
                    path: /login
                    port: api
                  initialDelaySeconds: 5
                  timeoutSeconds: 1

  - name: gordo-grafana-datasource-creator
    retryStrategy:
      limit: 5
    script:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-deploy:{{cleanup_version}}
      command: [bash]
      source: |
        echo "Creating grafana influxdb and postgres datasources for project {{project_name}}" \
        && curl -XPOST -H 'Content-Type: application/json' -d '{"name":"InfluxDB", "type":"influxdb", "url":"http://gordo-influx-{{project_name}}:8086", "access":"proxy", "database": "feeder", "isDefault":true, "password": "", "user": "", "basicAuth": false}' http://gordo-grafana-{{project_name}}:3000/api/datasources \
        && curl -XPOST -H 'Content-Type: application/json' -d '{"name": "Postgres-metadata","type": "postgres","url": "gordo-postgres-{{project_name}}","access": "proxy","database": "postgres","isDefault": false,"user": "postgres","jsonData": {"sslmode": "disable","postgresVersion": 1000,"timescaledb": false}}' http://gordo-grafana-{{project_name}}:3000/api/datasources \
        && echo "Uploading grafana dashboard for project {{project_name}}" \
        && curl -XPOST -d @/code/resources/grafana/dashboards/machines.json -H "Content-Type: application/json"  http://gordo-grafana-{{project_name}}:3000/api/dashboards/db
      resources:
        requests:
          memory: 50M
          cpu: 10m
        limits:
          memory: 1G


  - name: gordo-grafana
    steps:
    - - name: gordo-grafana-service
        template: gordo-grafana-service
    - - name: gordo-grafana-statefulset
        template: gordo-grafana-statefulset
    - - name: gordo-grafana-datasource-creator
        template: gordo-grafana-datasource-creator


  - name: gordo-postgres-service
    retryStrategy:
      limit: 5
    resource:
      action: apply
      manifest: |
        apiVersion: v1
        kind: Service
        metadata:
          name: gordo-postgres-{{project_name}}
          labels:
            app: gordo-postgres-{{project_name}}
            app.kubernetes.io/name: postgres
            app.kubernetes.io/component: service
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          selector:
            app: gordo-postgres-{{project_name}}
          ports:
          - port: 5432
            name: api
            targetPort: 5432
  - name: gordo-postgres-statefulset
    retryStrategy:
      limit: 5
    resource:
      action: apply
      successCondition: status.readyReplicas > 0
      manifest: |
        apiVersion: apps/v1
        kind: StatefulSet
        metadata:
          name: gordo-postgres-{{project_name}}
          labels:
            app: gordo-postgres-{{project_name}}
            app.kubernetes.io/name: postgresd-deployment
            app.kubernetes.io/component: postgresdb
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          serviceName: gordo-postgres-{{project_name}}
          volumeClaimTemplates:
            - metadata:
                name: postgres-storage-{{project_version}}
                annotations:
                  applications.gordo.equinor.com/project-name: "{{project_name}}"
                  applications.gordo.equinor.com/project-version: "{{project_version}}"
                labels:
                  applications.gordo.equinor.com/project-name: "{{project_name}}"
                  applications.gordo.equinor.com/project-version: "{{project_version}}"
                  app.kubernetes.io/part-of: gordo
                  app.kubernetes.io/managed-by: gordo
                {% if owner_references is defined %}
                ownerReferences: {{owner_references}}
                {% endif %}
              spec:
                accessModes: [ "ReadWriteOnce" ]
                storageClassName: "default"
                resources:
                  requests:
                    storage: 1Gi
          selector:
            matchLabels:
              app: gordo-postgres-{{project_name}}
          replicas: 1
          template:
            metadata:
              labels:
                app: gordo-postgres-{{project_name}}
              {% if owner_references is defined %}
              ownerReferences: {{owner_references}}
              {% endif %}
            spec:
              terminationGracePeriodSeconds: 10
              containers:
              - image: "postgres:11.2"
                imagePullPolicy: "IfNotPresent"
                name: gordo-postgres-{{project_name}}
                volumeMounts:
                  - name: postgres-storage-{{project_version}}
                    mountPath: /var/lib/postgresql/data/pgdata
                    subPath: postgres-db
                ports:
                  - name: api
                    containerPort: 5432
                resources:
                  requests:
                    memory: 256Mi
                    cpu: 50m
                env:
                  - name: POSTGRES_USER
                    value: postgres
                  - name: PGUSER
                    value: postgres
                  - name: POSTGRES_DB
                    value: postgres
                  - name: PGDATA
                    value: /var/lib/postgresql/data/pgdata
                  - name: POD_IP
                    valueFrom:
                      fieldRef:
                        apiVersion: v1
                        fieldPath: status.podIP
                livenessProbe:
                  exec:
                    command:
                      - sh
                      - -c
                      - exec pg_isready --host $POD_IP
                  failureThreshold: 6
                  initialDelaySeconds: 60
                  periodSeconds: 10
                  successThreshold: 1
                  timeoutSeconds: 5
                readinessProbe:
                  exec:
                    command:
                      - sh
                      - -c
                      - exec pg_isready --host $POD_IP
                  failureThreshold: 3
                  initialDelaySeconds: 5
                  periodSeconds: 5
                  successThreshold: 1
                  timeoutSeconds: 3


  - name: gordo-postgres
    steps:
    - - name: gordo-postgres-statefulset
        template: gordo-postgres-statefulset
    - - name: gordo-postgres-service
        template: gordo-postgres-service




  - name: gordo-watchman-to-postgres
    retryStrategy:
      limit: 5
    script:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-deploy:{{cleanup_version}}
      command: [bash]
      source: |
        echo "Feeding sql with metadata for project {{project_name}} using source ur http://$AMBASSADOR_HOST/gordo/v0/$PROJECT_NAME/ and postgres url gordo-postgres-$PROJECT_NAME " \
        && gordo-components workflow watchman-to-sql --watchman-address "http://$AMBASSADOR_HOST/gordo/v0/$PROJECT_NAME/" --sql-host "gordo-postgres-$PROJECT_NAME"
      env:
        - name: PROJECT_NAME
          value: "{{project_name}}"
        - name: AMBASSADOR_HOST
          value: "ambassador.{{ambassador_namespace}}"
      resources:
        requests:
          memory: 50M
          cpu: 10m
        limits:
          memory: 1G




  - name: model-builder
    retryStrategy:
      limit: 5
    metadata:
      labels:
        app: gordo-model-builder
        applications.gordo.equinor.com/project-name: {{project_name}}
        applications.gordo.equinor.com/project-version: "{{project_version}}"
    inputs:
      parameters:
      - name: model-name
      - name: metadata
      - name: model-config
      - name: data-config
      - name: data-provider
      - name: evaluation-config
    container:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-model-builder:{{gordo_version}}
      env:
      - name: OUTPUT_DIR
        value: "/gordo/models/{{project_name}}/{{project_version}}/{{'{{inputs.parameters.model-name}}'}}"
      - name: MODEL_REGISTER_DIR
        value: "/gordo/models/{{project_name}}/model_register"
      - name: MODEL_NAME
        value: {{ '"{{inputs.parameters.model-name}}" '}}
      - name: METADATA
        value: {{ '"{{inputs.parameters.metadata}}"' }}
      - name: MODEL_CONFIG
        value: {{ '"{{inputs.parameters.model-config}}"' }}
      - name: DL_SERVICE_AUTH_STR
        valueFrom:
          secretKeyRef:
            name: dlserviceauth
            key: tenant_id_secret
      - name: DATA_CONFIG
        value: {{ '"{{inputs.parameters.data-config}}"' }}
      - name: DATA_PROVIDER
        value: {{ '"{{inputs.parameters.data-provider}}"' }}
      - name: EVALUATION_CONFIG
        value: {{ '"{{inputs.parameters.evaluation-config}}"' }}
      volumeMounts:
      - name: azurefile
        mountPath: /gordo
      resources:
        requests:
          memory: "{{ model_builder_resources_requests_memory }}M"
          cpu: "{{ model_builder_resources_requests_cpu }}m"
        limits:
          memory: "{{ model_builder_resources_limits_memory }}M"
          cpu: "{{ model_builder_resources_limits_cpu }}m"

  - name: gordo-server-hpa
    retryStrategy:
      limit: 5
    inputs:
      parameters:
      - name: host-name
    resource:
      action: apply
      manifest: |
        ---
        apiVersion: autoscaling/v1
        kind: HorizontalPodAutoscaler
        metadata:
          name: "gordoserver-scaler-{{project_name}}"
          labels:
            app: "{{'{{inputs.parameters.host-name}}'}}"
            app.kubernetes.io/name: model-server
            app.kubernetes.io/component: service
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          scaleTargetRef:
            apiVersion: apps/v1
            kind: Deployment
            name: "{{'{{inputs.parameters.host-name}}'}}"
          minReplicas: 1
          maxReplicas: {{ max_server_replicas }}
          targetCPUUtilizationPercentage: 25


  - name: gordo-server-svc
    retryStrategy:
      limit: 5
    inputs:
      parameters:
      - name: host-name
    resource:
      action: apply
      manifest: |
        ---
        apiVersion: v1
        kind: Service
        metadata:
          name: "{{'{{inputs.parameters.host-name}}'}}"
          annotations:
            getambassador.io/config: |
              ---
              apiVersion: ambassador/v0
              kind:  Mapping
              name:  "{{'{{inputs.parameters.host-name}}'}}"
              prefix: "/gordo/v0/{{project_name}}/.+"
              prefix_regex: true
              rewrite: ""
              service: "{{'{{inputs.parameters.host-name}}'}}.{{namespace}}"
              timeout_ms: 600000  # 10 mins
          labels:
            app: "{{'{{inputs.parameters.host-name}}'}}"
            app.kubernetes.io/name: model-server
            app.kubernetes.io/component: service
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          selector:
            app: "{{'{{inputs.parameters.host-name}}'}}"
          ports:
          - port: 80
            name: http-gordo
            targetPort: http-api

  - name: gordo-server-istio
    retryStrategy:
      limit: 5
    inputs:
      parameters:
      - name: host-name
    resource:
      action: apply
      manifest: |
        ---
        apiVersion: networking.istio.io/v1alpha3
        kind: VirtualService
        metadata:
          name: "{{'{{inputs.parameters.host-name}}'}}"
          annotations:
          labels:
            app: "{{'{{inputs.parameters.host-name}}'}}"
            app.kubernetes.io/name: model-server
            app.kubernetes.io/component: VirtualService
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          hosts:
          - "*"
          gateways:
          - istio-system/istio-gateway
          http:
          - match:
            - uri:
                regex: "/gordo/v0/{{project_name}}/.+"
            route:
            - destination:
                host: "{{'{{inputs.parameters.host-name}}'}}"

  # SVC to notify watchman that a model has been built and can be served by the ML Server
  # This should only be temporary, as it's not _really_ a service, but used to notify Watchman
  # that the model is built and should be able to be contacted via the main server.
  # Here until we create a 'GordoModel' CRD which can then notify that the model is built.
  - name: gordo-notification-svc
    retryStrategy:
      limit: 5
    inputs:
      parameters:
        - name: model-name
        - name: host-name
    resource:
      action: apply
      manifest: |
        ---
        apiVersion: v1
        kind: Service
        metadata:
          name: "gordo-ntf-{{project_name}}-{{'{{inputs.parameters.model-name}}'}}"
          labels:
            app: "model-stache-{{'{{inputs.parameters.model-name}}'}}"
            app.kubernetes.io/name: model-server
            app.kubernetes.io/component: service
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
            applications.gordo.equinor.com/model-name: "{{'{{inputs.parameters.model-name}}'}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          clusterIP: None


  - name: gordo-server-deployment
    retryStrategy:
      limit: 5
    inputs:
      parameters:
      - name: host-name
    resource:
      action: apply
      successCondition: status.readyReplicas > 0
      manifest: |
        ---
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: "{{'{{inputs.parameters.host-name}}'}}"
          labels:
            app: "{{'{{inputs.parameters.host-name}}'}}"
            app.kubernetes.io/name: model-server-deployment
            app.kubernetes.io/component: server
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: "{{'{{inputs.parameters.host-name}}'}}"
          strategy:
            type: Recreate
          template:
            metadata:
              labels:
                app: "{{'{{inputs.parameters.host-name}}'}}"
            spec:
              containers:
                 - image: "{{ docker_registry }}/{{ docker_repository }}/gordo-model-server:{{gordo_version}}"
                   imagePullPolicy: "IfNotPresent"
                   name: "gordoserver-{{ project_name }}"
                   volumeMounts:
                     - mountPath: "/gordo"
                       name: gstor
                   ports:
                     - name: http-api
                       containerPort: 5555
                   livenessProbe:
                     httpGet:
                       path: /healthcheck
                       port: http-api
                     initialDelaySeconds: 600 # We give it a lot of time to load the model and start up
                     timeoutSeconds: 5
                   readinessProbe:
                     httpGet:
                       path: /healthcheck
                       port: http-api
                     initialDelaySeconds: 5
                     timeoutSeconds: 5
                   env:
                     - name: MODEL_COLLECTION_DIR
                       value: /gordo/models/{{project_name}}/{{project_version}}

                   resources:
                     requests:
                       memory: "{{ server_resources['requests']['memory'] }}M"
                       cpu: "{{ server_resources['requests']['cpu'] }}m"
                     limits:
                       memory: "{{ server_resources['limits']['memory'] }}M"
                       cpu: "{{ server_resources['limits']['cpu'] }}m"
              terminationGracePeriodSeconds: 1
              volumes:
                - name: gstor
                  persistentVolumeClaim:
                    claimName: "azurefile"

  - name: gordo-server
    inputs:
      parameters:
      - name: host-name
    steps:
    - - name: gordo-server-deployment
        template: gordo-server-deployment
        arguments:
          parameters: [{name: host-name, value: {{ '"{{inputs.parameters.host-name}}"' }} }]
    - - name: gordo-server-hpa
        template: gordo-server-hpa
        arguments:
          parameters: [{name: host-name, value: {{ '"{{inputs.parameters.host-name}}"' }} }]
      - name: gordo-server-svc
        template: gordo-server-svc
        arguments:
          parameters: [{name: host-name, value: {{ '"{{inputs.parameters.host-name}}"' }} }]
      - name: gordo-server-istio
        template: gordo-server-istio
        arguments:
          parameters: [{name: host-name, value: {{ '"{{inputs.parameters.host-name}}"' }} }]

  - name: gordo-client-para-limited # Runs gordo client, but with limited parallelization
    inputs:
      parameters:
      - name: model-name
      - name: train-start-date
      - name: data-provider
    steps:
    - - name: gordo-client-waiter
        template: gordo-client-waiter
    - - name: gordo-client
        template: gordo-client
        arguments:
          parameters: [{name: model-name, value: {{ '"{{inputs.parameters.model-name}}"' }}  },
                       {name: data-provider, value: {{ '"{{inputs.parameters.data-provider}}"' }}  },
                       {name: train-start-date, value: {{ '"{{inputs.parameters.train-start-date}}"' }}}
                      ]

  - name: gordo-client-waiter
    retryStrategy:
      limit: 5
    metadata:
      labels:
        app: gordo-client-waiter
        applications.gordo.equinor.com/project-name: "{{project_name}}"
        applications.gordo.equinor.com/project-version: "{{project_version}}"
    script:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-deploy:{{gordo_version}}
      command: [bash]
      source: |
        echo "Waiting until there is less than $GORDO_MAX_CLIENTS instances of gordo client for project_name: $GORDO_PROJECT_NAME, project-version=$GORDO_PROJECT_VERSION"
        function find_running_pods {
          export RUNNING_PODS=$(kubectl  get pods -l app=gordo-client,applications.gordo.equinor.com/project-name="$GORDO_PROJECT_NAME",applications.gordo.equinor.com/project-version="$GORDO_PROJECT_VERSION" --field-selector status.phase!=Succeeded,status.phase!=Failed)
          export NR_OF_RUNNING_PODS=$(echo "$RUNNING_PODS" | wc -l)
          let NR_OF_RUNNING_PODS=$NR_OF_RUNNING_PODS-1 # remove the header from the count
        }

        if [ $GORDO_MAX_CLIENTS -ge $GORDO_TOTAL_NR_OF_CLIENTS ]
        then
            echo "Found that total number of clients is less than the max number of parallel clients, so exiting successfully."
            exit 0
        fi
        let CHECK_INTERVAL_LENGTH=($GORDO_TOTAL_NR_OF_CLIENTS*5)+30
        sleep $[ ( $RANDOM % $CHECK_INTERVAL_LENGTH )  + 1 ]s
        find_running_pods
        echo "Found $NR_OF_RUNNING_PODS"
        while [ $NR_OF_RUNNING_PODS -ge $GORDO_MAX_CLIENTS ]; do
           sleep $CHECK_INTERVAL_LENGTH
           echo "."
           find_running_pods
        done
        echo "Found that there are now less than $GORDO_MAX_CLIENTS running pods, exiting successfully."


      resources:
        requests:
          memory: "100M"
          cpu: "2m"
        limits:
          memory: "200M"
          cpu: "100m"
      env:
      - name: GORDO_PROJECT_NAME
        value: "{{project_name}}"
      - name: GORDO_PROJECT_VERSION
        value: "{{project_version}}"
      - name: GORDO_MAX_CLIENTS
        value: "{{client_max_instances}}"
      - name : GORDO_TOTAL_NR_OF_CLIENTS
        value: "{{client_total_instances}}"

  - name: gordo-client
    retryStrategy:
      limit: 5 # Maybe the server is not up yet
    inputs:
      parameters:
      - name: model-name
      - name: train-start-date
      - name: data-provider
    metadata:
      labels:
        app: gordo-client
        applications.gordo.equinor.com/project-name: "{{project_name}}"
        applications.gordo.equinor.com/project-version: "{{project_version}}"
    script:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-model-builder:{{gordo_version}}
      command: [bash]
      source: |
        echo "Starting client prediction for machine $GORDO_CLIENT_TARGET" \
        && gordo-components client --project $GORDO_CLIENT_PROJECT --parallelism 2 --target $GORDO_CLIENT_TARGET --host $GORDO_CLIENT_HOST --port $GORDO_CLIENT_PORT --scheme $GORDO_CLIENT_SCHEME --metadata $GORDO_CLIENT_METADATA predict --influx-uri $GORDO_CLIENT_PREDICT_INFLUX_URI "$GORDO_TRAIN_START_DATE" $(date --iso-8601=second) --forward-resampled-sensors
      resources:
        requests:
          memory: "{{ client_resources_requests_memory }}M"
          cpu: "{{ client_resources_requests_cpu }}m"
        limits:
          memory: "{{ client_resources_limits_memory }}M"
          cpu: "{{ client_resources_limits_cpu }}m"
      env:
      - name: GORDO_CLIENT_TARGET
        value: {{ '"{{inputs.parameters.model-name}}" '}}
      - name: GORDO_TRAIN_START_DATE
        value: {{ '"{{inputs.parameters.train-start-date}}" '}}
      - name: DATA_PROVIDER # Environment variable read by the client
        value: {{ '"{{inputs.parameters.data-provider}}"' }}
      - name: GORDO_CLIENT_PROJECT
        value: "{{project_name}}"
      - name: GORDO_CLIENT_HOST
        value: "ambassador.{{ambassador_namespace}}"
      - name: GORDO_CLIENT_PORT
        value: "80"
      - name: GORDO_CLIENT_SCHEME
        value: "http"
      - name: GORDO_CLIENT_PREDICT_INFLUX_URI
        value: ":@gordo-influx-{{project_name}}:8086//feeder"
      - name: GORDO_CLIENT_INFLUX_RECREATE_DB
        value: "true"
      - name: GORDO_CLIENT_METADATA
        value: "version,{{project_version}}"
      - name: DL_SERVICE_AUTH_STR
        valueFrom:
          secretKeyRef:
            name: dlserviceauth
            key: tenant_id_secret

  - name: gordo-watchman-svc
    retryStrategy:
      limit: 5
    resource:
      action: apply
      manifest: |
        ---
        apiVersion: v1
        kind: Service
        metadata:
          name: "gordo-watchman-{{project_name}}"
          annotations:
            getambassador.io/config: |
              ---
              apiVersion: ambassador/v0
              kind:  Mapping
              name:  "gordo-watchman-{{project_name}}"
              prefix: "/gordo/v0/{{project_name}}/$"
              prefix_regex: true
              service: "gordo-watchman-{{project_name}}.{{namespace}}"
              timeout_ms: 600000  # 10 mins
          labels:
            app: "gordo-watchman-{{project_name}}"
            app.kubernetes.io/name: watchman
            app.kubernetes.io/component: service
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          selector:
            app: "gordo-watchman-{{project_name}}"
          ports:
          - port: 80
            name: http-gordo
            targetPort: http-api



  - name: gordo-watchman-istio
    retryStrategy:
      limit: 5
    resource:
      action: apply
      manifest: |
        ---
        apiVersion: networking.istio.io/v1alpha3
        kind: VirtualService
        metadata:
          name: "gordo-watchman-{{project_name}}"
          annotations:
          labels:
            app: "gordo-watchman-{{project_name}}"
            app.kubernetes.io/name: watchman
            app.kubernetes.io/component: VirtualService
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          hosts:
          - "*"
          gateways:
          - istio-system/istio-gateway
          http:
          - match:
            - uri:
                regex: "/gordo/v0/{{project_name}}/$"
            rewrite:
              uri: "/"
            route:
            - destination:
                host: "gordo-watchman-{{project_name}}"



  - name: gordo-watchman-deployment
    retryStrategy:
      limit: 5
    resource:
      action: apply
      successCondition: status.readyReplicas > 0
      manifest: |
        ---
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: "gordo-watchman-{{project_name}}"
          labels:
            app: "gordo-watchman-{{project_name}}"
            app.kubernetes.io/name: watchman-deployment
            app.kubernetes.io/component: watchman
            app.kubernetes.io/part-of: gordo
            app.kubernetes.io/managed-by: gordo
            applications.gordo.equinor.com/project-name: "{{project_name}}"
            applications.gordo.equinor.com/project-version: "{{project_version}}"
          {% if owner_references is defined %}
          ownerReferences: {{owner_references}}
          {% endif %}
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: "gordo-watchman-{{project_name}}"
          strategy:
            type: Recreate
          template:
            metadata:
              labels:
                app: "gordo-watchman-{{project_name}}"
            spec:
              containers:
                 - image: "{{ docker_registry }}/{{ docker_repository }}/gordo-watchman:{{gordo_version}}"
                   imagePullPolicy: "IfNotPresent"
                   name: "gordo-watchman-{{project_name}}"
                   ports:
                     - name: http-api
                       containerPort: 5556
                   readinessProbe:
                     httpGet:
                       path: /healthcheck
                       port: http-api
                     initialDelaySeconds: 5
                     timeoutSeconds: 2
                   env:
                     - name: TARGET_NAMES
                       value: "{{target_names}}"
                     - name: PROJECT_NAME
                       value: {{project_name}}
                     - name: PROJECT_VERSION
                       value: "{{project_version}}"
                     - name: AMBASSADOR_NAMESPACE
                       value: "{{ambassador_namespace}}"
                   resources:
                     requests:
                       memory: 500M
                       cpu: 10m
                     limits:
                       memory: 1G
                       cpu: 1
              terminationGracePeriodSeconds: 1


  - name: gordo-watchman
    steps:
    - - name: gordo-watchman-deployment
        template: gordo-watchman-deployment
    - - name: gordo-watchman-svc
        template: gordo-watchman-svc
    - - name: gordo-watchman-istio
        template: gordo-watchman-istio

  - name: influx-cleanup
    activeDeadlineSeconds: 300
    retryStrategy:
      limit: 5
    script:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-deploy:{{gordo_version}}
      command: [bash]
      source: |
        echo "Deleting influx, grafana and PVC for {{project_name}} different than {{project_version}}" \
         && kubectl delete statefulset -l applications.gordo.equinor.com/project-name={{project_name}},applications.gordo.equinor.com/project-version!={{project_version}} \
         && kubectl delete svc -l applications.gordo.equinor.com/project-name={{project_name}},applications.gordo.equinor.com/project-version!={{project_version}},app.kubernetes.io/name=influx \
         && kubectl delete svc -l applications.gordo.equinor.com/project-name={{project_name}},applications.gordo.equinor.com/project-version!={{project_version}},app.kubernetes.io/name=grafana \
         && kubectl delete $(kubectl get pvc -l app=gordo-influx-{{project_name}} -o name | grep -v influx-storage-{{project_version}}  ) || : \
         && sleep 5
      resources:
        requests:
          memory: 50M
          cpu: 10m
        limits:
          memory: 1G

  - name: postgres-cleanup
    activeDeadlineSeconds: 300
    retryStrategy:
      limit: 5
    script:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-deploy:{{gordo_version}}
      command: [bash]
      source: |
        echo "Deleting postgres PVC for {{project_name}} different than {{project_version}}" \
         && kubectl delete svc -l applications.gordo.equinor.com/project-name={{project_name}},applications.gordo.equinor.com/project-version!={{project_version}},app.kubernetes.io/name=postgres \
         && kubectl delete $(kubectl get pvc -l app=gordo-postgres-{{project_name}} -o name | grep -v postgres-storage-{{project_version}} ) || : \
         && sleep 5
      resources:
        requests:
          memory: 50M
          cpu: 10m
        limits:
          memory: 1G

  - name: cleanup
    retryStrategy:
      limit: 5
    script:
      image: {{ docker_registry }}/{{ docker_repository }}/gordo-deploy:{{gordo_version}}
      command: [bash]
      source: |
        echo "Deleting gordo deployments and services for project {{project_name}} different than {{project_version}}" \
         && kubectl delete deployments -l applications.gordo.equinor.com/project-name={{project_name}},applications.gordo.equinor.com/project-version!={{project_version}} \
         && kubectl delete svc -l applications.gordo.equinor.com/project-name={{project_name}},applications.gordo.equinor.com/project-version!={{project_version}} \
         && kubectl delete hpa -l applications.gordo.equinor.com/project-name={{project_name}},applications.gordo.equinor.com/project-version!={{project_version}}
      resources:
        requests:
          memory: 50M
          cpu: 10m
        limits:
          memory: 1G


  - name: sql-and-cleanup
    steps:
    - - name: cleanup
        template: cleanup
        {%if enable_influx %}
      - name: gordo-watchman-to-postgres
        template: gordo-watchman-to-postgres
        {% endif %}


  - name: build-single-machine
    inputs:
      parameters:
        - name: model-name
        - name: model-config
        - name: metadata
        - name: data-config
        - name: data-provider
        - name: evaluation-config
    steps:
      -  - name: build-model
           template: model-builder
           arguments:
            parameters: [{name: model-name, value: {{ '"{{inputs.parameters.model-name}}"' }}  },
                         {name: model-config, value: {{ '"{{inputs.parameters.model-config}}"' }} },
                         {name: metadata, value: {{'"{{inputs.parameters.metadata}}"'}} },
                         {name: data-config, value: {{ '"{{inputs.parameters.data-config}}"' }}},
                         {name: data-provider, value: {{ '"{{inputs.parameters.data-provider}}"' }}},
                         {name: evaluation-config, value: {{ '"{{inputs.parameters.evaluation-config}}"' }}}
            ]
      -  - name: model-notification-svc
           template: gordo-notification-svc
           arguments:
             parameters:
               - name: model-name
                 value: {{ '"{{inputs.parameters.model-name}}"' }}
               - name: host-name
                 value: "ml-server-{{ project_name }}"
  - name: ml-server
    inputs:
      parameters:
        - name: host-name
    steps:
      -  - name: serve-model
           template: gordo-server
           arguments:
             parameters: [{name: host-name, value: {{ '"{{inputs.parameters.host-name}}"' }} }]

  - name: do-all
    dag:
      tasks:
        - name: ensure-single-workflow
          template: ensure-single-workflow
        - name: watchman
          template: gordo-watchman
          dependencies:
            - ensure-single-workflow
        {% for machine in machines %}
        - name: model-builder-{{ machine.name }}
          template: build-single-machine
          arguments:
            parameters: [{name: model-name, value: "{{ machine.name }}"},
                         {name: model-config, value: "{{ machine.model }}"},
                         {name: metadata, value: "{{ machine.metadata }}"},
                         {name: data-config, value: "{{ machine.dataset.to_dict() }}"},
                         {name: data-provider, value: "{{ machine.data_provider.to_dict() }}"},
                         {name: evaluation-config, value: "{{ machine.evaluation}}"},
            ]

          dependencies:
            - watchman
            - ml-server
        {% endfor %}
        - name: postgres-cleanup
          template: postgres-cleanup
          dependencies:
            - ensure-single-workflow
        - name: influx-cleanup
          template: influx-cleanup
          dependencies:
            - ensure-single-workflow
        {%if enable_influx %}
        - name: gordo-postgres
          template: gordo-postgres
          dependencies:
            - postgres-cleanup
        - name: gordo-influx
          template: gordo-influx
          dependencies:
            - influx-cleanup
        - name: gordo-grafana
          template: gordo-grafana
          dependencies:
            - influx-cleanup
        - name: ml-server
          template: ml-server
          arguments:
            parameters:
              - name: host-name
                value: "ml-server-{{ project_name }}"
          dependencies:
            - ensure-single-workflow
        {% for machine in machines %}
        {% if machine.runtime["influx"]["enable"] %}
        - name: gordo-client-{{machine.name}}
          template: gordo-client-para-limited
          arguments:
            parameters:
              - name: model-name
                value: "{{ machine.name}}"
              - name: train-start-date
                value: "{{ machine.dataset.train_start_date }}"
              - name: data-provider
                value: "{{ machine.data_provider.to_dict() }}"
          dependencies:
            - ml-server
            - gordo-influx
            - model-builder-{{ machine.name }}
        {% endif %}
        {% endfor %}
        {% endif %}
