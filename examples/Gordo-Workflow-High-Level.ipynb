{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Gordo from only a config file\n",
    "\n",
    "This is a higher level example of how gordo works.\n",
    "\n",
    "Train a model from a config file.\n",
    "\n",
    "---\n",
    "** Some slight difference in how it _actually_ works, in that we normally use some resources from `gordo-infrastructure` for parsing the config that we don't have access to here. Yet.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "from dateutil.parser import isoparse\n",
    "\n",
    "from gordo_components import serializer\n",
    "from gordo_components.builder import build_model\n",
    "from gordo_components.data_provider.providers import DataLakeProvider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "\"\"\"\n",
    "machines:\n",
    "\n",
    "  - name: asgb-morvin\n",
    "    dataset:\n",
    "      tags: #list of tags\n",
    "        - asgb.19ZT3950%2FY%2FPRIM\n",
    "        - asgb.19PST3925%2FDispMeasOut%2FPRIM\n",
    "        - asgb.19PT3905%2FY%2F5mMID\n",
    "      train_start_date: 2014-07-01T00:10:00+00:00\n",
    "      train_end_date: 2015-01-01T00:00:00+00:00\n",
    "    metadata:\n",
    "      my-special-metadata-attr: is awesome!\n",
    "\n",
    "model:\n",
    "  sklearn.pipeline.Pipeline:\n",
    "    steps:\n",
    "      - sklearn.preprocessing.data.MinMaxScaler\n",
    "      - gordo_components.model.models.KerasAutoEncoder:\n",
    "          kind: feedforward_hourglass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate how Gordo extract required information from a config file\n",
    "\n",
    "##### Note:\n",
    "This is _not_ exactly how it's actually done. We use some resources available in `gordo-infrastructure` which is not available from `gordo-components`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a normal dict\n",
    "config = yaml.load(config, Loader=yaml.BaseLoader)\n",
    "\n",
    "# Model configuration\n",
    "model_config = config['model']\n",
    "\n",
    "# In this case, we only build a model for a single machine\n",
    "machine_config = config['machines'][0]\n",
    "\n",
    "# TODO: This is the ugliest portion, as we normally use resources [`Machine`] found in `gordo-infrastructure`\n",
    "data_config  = {\n",
    "    \"type\": \"TimeSeriesDataset\",  # We want to use `DataLakeBackedDataset` for data acquisition\n",
    "    \"from_ts\": isoparse(machine_config['dataset']['train_start_date']),\n",
    "    \"to_ts\": isoparse(machine_config['dataset']['train_end_date']),\n",
    "    \"tag_list\": machine_config['dataset']['tags'],\n",
    "    \"data_provider\": DataLakeProvider(storename=\"dataplatformdlsprod\", interactive=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model from data and model configs\n",
    "\n",
    "This also optionally takes and will return metadata `dict` updated with various model building events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe, metadata = build_model(\n",
    "    name=config['model'],\n",
    "    model_config=model_config, \n",
    "    data_config=data_config,\n",
    "    metadata=machine_config['metadata']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The trained model/pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('step_0', MinMaxScaler(copy=True, feature_range=(0, 1))), ('step_1', <gordo_components.model.models.KerasAutoEncoder object at 0x7f7ac48ea908>)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata from the model and build process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  resolution: 10T\n",
      "  tag_list: [asgb.19ZT3950%2FY%2FPRIM, asgb.19PST3925%2FDispMeasOut%2FPRIM, asgb.19PT3905%2FY%2F5mMID]\n",
      "  train_end_date: 2015-01-01 00:00:00+00:00\n",
      "  train_start_date: 2014-07-01 00:10:00+00:00\n",
      "model:\n",
      "  data_query_duration_sec: 21.27293300628662\n",
      "  model_builder_version: 0.9.1.dev3+g9da7836.d20190225\n",
      "  model_config:\n",
      "    sklearn.pipeline.Pipeline:\n",
      "      steps:\n",
      "      - sklearn.preprocessing.data.MinMaxScaler\n",
      "      - gordo_components.model.models.KerasAutoEncoder: {kind: feedforward_symetric}\n",
      "  model_creation_date: '2019-02-25 12:21:38.595111+01:00'\n",
      "  model_training_duration_sec: 3.5922129154205322\n",
      "user-defined: {my-special-metadata-attr: is awesome!}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yaml.dump(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
