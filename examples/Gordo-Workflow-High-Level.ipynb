{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Gordo from only a config file\n",
    "\n",
    "This is a higher level example of how gordo works.\n",
    "\n",
    "Train a model from a config file.\n",
    "\n",
    "---\n",
    "** Some slight difference in how it _actually_ works, in that we normally use some resources from `gordo-infrastructure` for parsing the config that we don't have access to here. Yet.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "from dateutil.parser import isoparse\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from gordo_components import serializer\n",
    "from gordo_components.builder import build_model\n",
    "from gordo_components.data_provider.providers import DataLakeProvider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "\"\"\"\n",
    "machines:\n",
    "\n",
    "  - name: statfjord-lstm-010613-010614\n",
    "    dataset:\n",
    "      tags: #list of tags \n",
    "        - DQ-PT-T-B30L%2FMeas1%2FPRIM\n",
    "        - DQ-TT-T-B30L%2FMeas1%2FPRIM\n",
    "        - FT-24684%2FMeas%2FPRIM\n",
    "        - PT-13005%2FMeasA%2FPRIM\n",
    "        - PT-13009%2FMeasA%2FPRIM\n",
    "        - TT-13092%2FMeas1%2FPRIM\n",
    "      train_start_date: 2013-06-01T00:10:00+00:00\n",
    "      train_end_date: 2014-06-01T00:00:00+00:00\n",
    "    metadata:\n",
    "      metadata_name: statfjord_test\n",
    "    \n",
    "model:\n",
    "  sklearn.pipeline.Pipeline:\n",
    "    steps:\n",
    "      - sklearn.preprocessing.data.StandardScaler\n",
    "      - gordo_components.model.models.KerasLSTMAutoEncoder:\n",
    "          kind: lstm_autoencoder\n",
    "          lookback_window: 144\n",
    "          encoding_dim: [4,3]\n",
    "          decoding_dim: [3,4]\n",
    "          out_func: linear\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate how Gordo extract required information from a config file\n",
    "\n",
    "##### Note:\n",
    "This is _not_ exactly how it's actually done. We use some resources available in `gordo-infrastructure` which is not available from `gordo-components`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a normal dict\n",
    "config = yaml.load(config, Loader=yaml.BaseLoader)\n",
    "\n",
    "# Model configuration\n",
    "model_config = config['model']\n",
    "\n",
    "# In this case, we only build a model for a single machine\n",
    "machine_config = config['machines'][0]\n",
    "\n",
    "# TODO: This is the ugliest portion, as we normally use resources [`Machine`] found in `gordo-infrastructure`\n",
    "data_config  = {\n",
    "    \"type\": \"TimeSeriesDataset\",  # We want to use `DataLakeBackedDataset` for data acquisition\n",
    "    \"from_ts\": isoparse(machine_config['dataset']['train_start_date']),\n",
    "    \"to_ts\": isoparse(machine_config['dataset']['train_end_date']),\n",
    "    \"tag_list\": machine_config['dataset']['tags'],\n",
    "    \"data_provider\": DataLakeProvider(storename=\"dataplatformdlsprod\", interactive=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model from data and model configs\n",
    "\n",
    "This also optionally takes and will return metadata `dict` updated with various model building events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code DLWHFAPBF to authenticate.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found no data providers able to download the tag DQ-PT-T-B30L%2FMeas1%2FPRIM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fb4ceef53b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmachine_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/equinor/repositories/gordo-components/gordo_components/builder/build_model.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(model_config, data_config, metadata)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fetching training data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtime_elapsed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/equinor/repositories/gordo-components/gordo_components/dataset/datasets.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfrom_ts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_ts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         )\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/equinor/repositories/gordo-components/gordo_components/dataset/base.py\u001b[0m in \u001b[0;36mjoin_timeseries\u001b[0;34m(dataframes, resampling_startpoint, resolution)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mresampled_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             startpoint_sametz = resampling_startpoint.astimezone(\n\u001b[1;32m     62\u001b[0m                 \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtzinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/equinor/repositories/gordo-components/gordo_components/data_provider/providers.py\u001b[0m in \u001b[0;36mload_dataframes\u001b[0;34m(self, from_ts, to_ts, tag_list)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         yield from load_dataframes_from_multiple_providers(\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mdata_providers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         )\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/equinor/repositories/gordo-components/gordo_components/data_provider/providers.py\u001b[0m in \u001b[0;36mload_dataframes_from_multiple_providers\u001b[0;34m(data_providers, from_ts, to_ts, tag_list)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# The else branch is executed if the break is not called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found no data providers able to download the tag {tag}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreaders_tags\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreaders_to_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreaders_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found no data providers able to download the tag DQ-PT-T-B30L%2FMeas1%2FPRIM"
     ]
    }
   ],
   "source": [
    "pipe, metadata = build_model(\n",
    "    model_config=model_config, \n",
    "    data_config=data_config,\n",
    "    metadata=machine_config['metadata']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The trained model/pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata from the model and build process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yaml.dump(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gordo_comp",
   "language": "python",
   "name": "gordo_comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
