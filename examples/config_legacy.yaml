# Note that this is a Gordo machine config. In production, this config is used as the main part in specifying a
# deployable  Gordo. A Gordo CRD includes a section defining the version and name of the project/Gordo.
# See https://github.com/equinor/gordo-controller/blob/master/example-gordo.yaml for a full example.
machines:

  - name: ct-23-0001 #1st machine
    dataset:
      tags: #list of tags for 1st machine
        - TAG 1
        - TAG 2
        - TAG 3
      train_start_date: 2016-11-07T09:11:30+01:00
      train_end_date: 2018-09-15T03:01:00+01:00
    runtime:
      server:
        resources:
          requests: # The resources we require reserved
            memory: 1700 # Request 1.7G of memory
            cpu: 2000 # Request two cores, while e.g. 250 would mean a quarter core
          limits: # The resources we are limited to using.
            memory: 2000 #Kill the server if it uses more than 2GB
            cpu: 2000 #Throttle the server to never using more than 2 cores


  - name: ct-23-0002 #2nd machine
    dataset:
      resolution: 2T
      tags: #list of tags for 2nd machine
        - TAG 1
        - TAG 2
        - TAG 3
      train_start_date: 2018-05-20T01:00:04+02:00
      train_end_date: 2019-05-10T15:05:50+02:00
    runtime:
      server: #one can override just a single resource request as well
        resources:
          requests:
            memory: 1000
      influx: # Dont push results for this single model to influx
        enable: False

  - name: ct-23-0003 #3rd machine
    dataset:
      tags: #list of tags for 3rd machine
        - TAG 1
        - TAG 2
        - TAG 3
      train_start_date: 2018-09-15T13:03:04+02:00
      train_end_date: 2019-03-11T11:05:10+02:00

globals:
  runtime:
    influx: # Change to False to disable influx. Default value: True
      enable: True
    builder: # The model builder can only be customized globally, any per-machine settings will be ignored.
      resources:
        requests:
          memory: 4000 #4 GB of memory
          cpu: 2000 #2 cores
        # since limits are not specified, the defaults are used (3GB memory and 32 cores CPU), but since the memory
        # limit (3GB) is less than request(4GB), which is not allowed, the memory limit will be lifted to match
        # the memory request (4GB).
  model:
    sklearn.pipeline.Pipeline:
      steps:
        - sklearn.preprocessing.data.MinMaxScaler
        - gordo_components.model.models.KerasAutoEncoder:
            kind: feedforward_hourglass
